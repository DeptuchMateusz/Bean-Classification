{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etap 2 KM 2 - inżynieria cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/our_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far zauważyliśmy:\n",
    "- brak brakujących wartości  \n",
    "- kolumna Compactness zdecydowanie do usunięcia i może kilka innych\n",
    "- brak dużej ilości outlierów (tam wyżej niby były ale to taki rozkład był więc jednak nie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. USUNIĘCIE ZBĘDNYCH KOLUMN - korelacja > 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ENCODING  \n",
    "Zamiana zmiennej kategorycznej - nazw klas fasolek, przy użyciu one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MODELOWANIE DWUSTOPNIOWE ENCODING - one vs. rest dla fasolki Bombay\n",
    "Do modelu rozdzielającego Bombay od reszty transformujemy kolumnę zamieniając wartość na 1, gdy jest to bombay 0, gdy nie jest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4990         SIRA\n",
       "3361        SEKER\n",
       "10806    DERMASON\n",
       "9320        HOROZ\n",
       "6645        HOROZ\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_b = y_train.map(lambda x: 1 if x == 'BOMBAY' else 0)\n",
    "y_val_b = y_val.map(lambda x: 1 if x == 'BOMBAY' else 0)\n",
    "y_test_b = y_test.map(lambda x: 1 if x == 'BOMBAY' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "clf_b = RandomForestClassifier(n_estimators=1, max_depth=100, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "clf_b.fit(X_train, y_train_b)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = clf_b.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_b, y_val_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = sklearn.metrics.f1_score(y_val_b, y_val_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val_b, y_val_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val_b, y_val_pred)\n",
    "\n",
    "# Display precision and recall\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOMBAY  \n",
    "n_estimators = 1, max_depth = 100:  \n",
    "Accuracy: 1.0  \n",
    "F1 Score: 1.0  \n",
    "Precision: 1.0  \n",
    "Recall: 1.0  \n",
    "\n",
    "n_estimators = 100, max_depth = 3:\n",
    "\n",
    "Accuracy: 0.9995625546806649  \n",
    "F1 Score: 0.9940828402366864  \n",
    "Precision: 1.0  \n",
    "Recall: 0.9882352941176471  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ONE VS ALL \n",
    "w sumie spróbujmy one vs rest dla wszystkich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9881889763779528\n",
      "F1 Score: 0.9597615499254843\n",
      "Precision: 0.9698795180722891\n",
      "Recall: 0.9498525073746312\n"
     ]
    }
   ],
   "source": [
    "y_train_s = y_train.map(lambda x: 1 if x == 'SEKER' else 0)\n",
    "y_val_s = y_val.map(lambda x: 1 if x == 'SEKER' else 0)\n",
    "y_test_s = y_test.map(lambda x: 1 if x == 'SEKER' else 0)\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "clf = RandomForestClassifier(n_estimators=30, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "clf.fit(X_train, y_train_s)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_s, y_val_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = sklearn.metrics.f1_score(y_val_s, y_val_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val_s, y_val_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val_s, y_val_pred)\n",
    "\n",
    "# Display precision and recall\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEKER  \n",
    "n = 30, max = 10 -> 0.6s  \n",
    "Accuracy: 0.9881889763779528  \n",
    "F1 Score: 0.9597615499254843  \n",
    "Precision: 0.9698795180722891  \n",
    "Recall: 0.9498525073746312  \n",
    "\n",
    "n = 1, max = 100  \n",
    "Accuracy: 0.9768153980752406  \n",
    "F1 Score: 0.9212481426448736  \n",
    "Precision: 0.9281437125748503  \n",
    "Recall: 0.9144542772861357  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9540682414698163\n",
      "F1 Score: 0.9124270225187657\n",
      "Precision: 0.9193277310924369\n",
      "Recall: 0.9056291390728477\n"
     ]
    }
   ],
   "source": [
    "y_train_d = y_train.map(lambda x: 1 if x == 'DERMASON' else 0)\n",
    "y_val_d = y_val.map(lambda x: 1 if x == 'DERMASON' else 0)\n",
    "y_test_d = y_test.map(lambda x: 1 if x == 'DERMASON' else 0)\n",
    "\n",
    "# Create a RandomForestClassifier model\n",
    "clf_d = RandomForestClassifier(n_estimators=10, max_depth=70, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "clf_d.fit(X_train, y_train_d)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_val_pred = clf_d.predict(X_val)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val_d, y_val_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = sklearn.metrics.f1_score(y_val_d, y_val_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val_d, y_val_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val_d, y_val_pred)\n",
    "\n",
    "# Display precision and recall\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPR czy SVM działa lepiej po usunięciu Bombaya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO FINISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20308\\3029837127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscaling\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX_train_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_filtered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#tu encodowane dane dają błąd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# If input is scalar raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    762\u001b[0m                     \u001b[1;34m\"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=nan.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#TO FINISH - REMOVE ROWS THAT WERE PREDICTED AS BOMBAY BY CLF_B\n",
    "X_train_filtered = None\n",
    "y_train_filtered = None\n",
    "X_val_filtered = None\n",
    "y_val_filtered = None\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore')\n",
    "#enc.fit(y_train_filtered.to_frame())\n",
    "#y_encoded_filtered = pd.DataFrame(enc.transform(y_train_filtered.to_frame()).toarray(),columns=enc.get_feature_names(['Class']))\n",
    "\n",
    "scaling = MinMaxScaler()\n",
    "X_train_filtered = scaling.fit_transform(X_train_filtered)\n",
    "\n",
    "#tu encodowane dane dają błąd \n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1, random_state=42, decision_function_shape='ovo').fit(X_train_filtered, y_train_filtered)\n",
    "print(\"SVM accuracy: {:.2f}\".format(svm.score(X_val_filtered, y_val_filtered)))\n",
    "print(\"SVM f1 score: {:.2f}\".format(sklearn.metrics.f1_score(y_val_filtered, svm.predict(X_val_filtered), average='weighted')))\n",
    "#uwaga na zmiane parametrow bo moze sie robic kilka dni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 ENCODING DLA CAŁOŚCI + RÓZNE MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(y_train.to_frame())\n",
    "y_encoded = pd.DataFrame(enc.transform(y_train.to_frame()).toarray(),columns=enc.get_feature_names(['Class']))\n",
    "y_val_encoded = pd.DataFrame(enc.transform(y_val.to_frame()).toarray(),columns=enc.get_feature_names(['Class']))\n",
    "y_test_encoded = pd.DataFrame(enc.transform(y_test.to_frame()).toarray(),columns=enc.get_feature_names(['Class']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler()\n",
    "X_train = scaling.fit_transform(X_train)\n",
    "X_test = scaling.transform(X_test)\n",
    "X_val = scaling.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kodzenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy: 0.92\n",
      "SVM f1 score: 0.92\n"
     ]
    }
   ],
   "source": [
    "#tu encodowane dane dają błąd \n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1, random_state=42, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "print(\"SVM accuracy: {:.2f}\".format(svm.score(X_val, y_val)))\n",
    "print(\"SVM f1 score: {:.2f}\".format(sklearn.metrics.f1_score(y_val, svm.predict(X_val), average='weighted')))\n",
    "#uwaga na zmiane parametrow bo moze sie robic kilka dni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM accuracy: 0.92\n",
    "SVM f1 score: 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accuracy: 0.89\n",
      "Tree f1 score: 0.89\n"
     ]
    }
   ],
   "source": [
    "#tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=10000, random_state=42)\n",
    "tree.fit(X_train, y_encoded)\n",
    "y_hat = tree.predict(X_val)\n",
    "print(\"Tree accuracy: {:.2f}\".format(tree.score(X_val, y_val_encoded)))\n",
    "print(\"Tree f1 score: {:.2f}\".format(sklearn.metrics.f1_score(y_val_encoded, y_hat, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree accuracy: 0.89  \n",
    "Tree f1 score: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accuracy: 0.89\n",
      "Tree f1 score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=10000, random_state=42, criterion='entropy')\n",
    "tree.fit(X_train, y_encoded)\n",
    "y_hat = tree.predict(X_val)\n",
    "print(\"Tree accuracy: {:.2f}\".format(tree.score(X_val, y_val_encoded)))\n",
    "print(\"Tree f1 score: {:.2f}\".format(sklearn.metrics.f1_score(y_val_encoded, y_hat, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
