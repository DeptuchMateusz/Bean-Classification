{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:11:08.620306Z",
     "start_time": "2024-04-21T17:11:08.211108Z"
    }
   },
   "id": "58bd9b9a6374e0b5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:19:41.991441Z",
     "start_time": "2024-04-21T17:19:41.878945Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Data/our_data.csv')\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "df_for_validators = pd.read_csv('../../Data/validator_data.csv')\n",
    "X_for_validators = df_for_validators.drop('Class', axis=1)\n",
    "y_for_validators = df_for_validators['Class']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.drop(['Compactness','EquivDiameter', 'Area'], axis=1)\n",
    "X_val = X_val.drop(['Compactness','EquivDiameter','Area'], axis=1)\n",
    "X_test = X_test.drop(['Compactness','EquivDiameter','Area'], axis=1)\n",
    "X_for_validators = X_for_validators.drop(['Compactness','EquivDiameter','Area'], axis=1)\n",
    "cols = X_train.columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scaling = sklearn.preprocessing.PowerTransformer(method='box-cox')\n",
    "X_train = scaling.fit_transform(X_train)\n",
    "X_test = scaling.transform(X_test)\n",
    "X_val = scaling.transform(X_val)\n",
    "X_for_validators = scaling.transform(X_for_validators)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)\n",
    "X_val = pd.DataFrame(X_val, columns=cols)\n",
    "X_for_validators = pd.DataFrame(X_for_validators, columns=cols)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(y_train.to_frame())\n",
    "y_encoded = pd.DataFrame(enc.transform(y_train.to_frame()).toarray(),columns=enc.get_feature_names_out(['Class']))\n",
    "y_val_encoded = pd.DataFrame(enc.transform(y_val.to_frame()).toarray(),columns=enc.get_feature_names_out(['Class']))\n",
    "y_test_encoded = pd.DataFrame(enc.transform(y_test.to_frame()).toarray(),columns=enc.get_feature_names_out(['Class']))\n",
    "y_for_validators_encoded = pd.DataFrame(enc.transform(y_for_validators.to_frame()).toarray(),columns=enc.get_feature_names_out(['Class']))\n",
    "\n",
    "#standard encoding 0,1,2,...\n",
    "labelencoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_encoded2 = pd.DataFrame(labelencoder.fit_transform(y_train))\n",
    "y_val_encoded2 = pd.DataFrame(labelencoder.fit_transform(y_val))\n",
    "y_test_encoded2 = pd.DataFrame( labelencoder.fit_transform(y_test))\n",
    "y_for_validators_encoded2 = pd.DataFrame(labelencoder.fit_transform(y_for_validators))\n",
    "\n",
    "\n",
    "class_names = ['BARBUNYA', 'BOMBAY', 'CALI', 'DERMASON', 'HOROZ', 'SEKER', 'SIRA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      Class_BARBUNYA  Class_BOMBAY  Class_CALI  Class_DERMASON  Class_HOROZ  \\\n0                0.0           0.0         0.0             0.0          0.0   \n1                0.0           0.0         0.0             0.0          0.0   \n2                0.0           0.0         0.0             1.0          0.0   \n3                0.0           0.0         0.0             0.0          1.0   \n4                0.0           0.0         0.0             0.0          1.0   \n...              ...           ...         ...             ...          ...   \n7616             0.0           0.0         0.0             0.0          0.0   \n7617             0.0           0.0         0.0             0.0          0.0   \n7618             1.0           0.0         0.0             0.0          0.0   \n7619             0.0           0.0         0.0             1.0          0.0   \n7620             0.0           0.0         0.0             1.0          0.0   \n\n      Class_SEKER  Class_SIRA  \n0             0.0         1.0  \n1             1.0         0.0  \n2             0.0         0.0  \n3             0.0         0.0  \n4             0.0         0.0  \n...           ...         ...  \n7616          0.0         1.0  \n7617          1.0         0.0  \n7618          0.0         0.0  \n7619          0.0         0.0  \n7620          0.0         0.0  \n\n[7621 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class_BARBUNYA</th>\n      <th>Class_BOMBAY</th>\n      <th>Class_CALI</th>\n      <th>Class_DERMASON</th>\n      <th>Class_HOROZ</th>\n      <th>Class_SEKER</th>\n      <th>Class_SIRA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7616</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7617</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7618</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7619</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7620</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7621 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:19:42.473094Z",
     "start_time": "2024-04-21T17:19:42.463253Z"
    }
   },
   "id": "dc64d5efb6d93095"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      0\n0     6\n1     5\n2     3\n3     4\n4     4\n...  ..\n7616  6\n7617  5\n7618  0\n7619  3\n7620  3\n\n[7621 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7616</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7617</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7618</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7619</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7620</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>7621 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:19:43.364314Z",
     "start_time": "2024-04-21T17:19:43.353668Z"
    }
   },
   "id": "9e2a7401f726de9b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "\n",
    "def map_gambling(df):\n",
    "    \"\"\"\n",
    "    This function maps the 'CAT_GAMBLING' column in the dataframe from string values to integer values.\n",
    "    'No' is mapped to 0, 'Low' is mapped to 1, and 'High' is mapped to 2.\n",
    "    \"\"\"\n",
    "    df['CAT_GAMBLING'] = df['CAT_GAMBLING'].map({'No': 0, 'Low': 1, 'High': 2})\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_x_from_y(df, target='DEFAULT'):\n",
    "    \"\"\"\n",
    "    This function splits the dataframe into features (X) and target (y) based on the target column name provided.\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def remove_columns_with_high_correlation(df):\n",
    "    columns_to_remove = [\"T_CLOTHING_12\", \"T_ENTERTAINMENT_12\", \"T_GROCERIES_12\", \"T_GROCERIES_6\", \"T_HEALTH_12\",\n",
    "                         \"T_TAX_12\", \"T_TAX_6\",\n",
    "                         \"T_TRAVEL_12\", \"T_TRAVEL_6\", \"T_UTILITIES_12\", \"T_UTILITIES_6\", \"T_EXPENDITURE_12\",\n",
    "                         \"T_EXPENDITURE_6\"]\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "    return df\n",
    "\n",
    "\n",
    "def automatic_remove_outliers(df):\n",
    "    clf = KNN(contamination=0.04)\n",
    "    clf.fit(df)\n",
    "    df['outliers'] = clf.labels_\n",
    "    df['outliers'] = df['outliers'].map({'No': 0, 'Yes': 1})\n",
    "    df = df[df['outliers'] == 0]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_my_metrics(model, X_train, X_val, y_train, y_val):\n",
    "    \"\"\"\n",
    "    This function fits the model with the training data and makes predictions on the validation data.\n",
    "    It then calculates and returns the accuracy, precision, recall, and f1 score of the model.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def cox_box_transform(X_train, X_val):\n",
    "    \"\"\"\n",
    "    This function applies the Yeo-Johnson power transformation to the training and validation data.\n",
    "    \"\"\"\n",
    "    cox_box_model = PowerTransformer(method='yeo-johnson')\n",
    "    X_train_transformed = cox_box_model.fit_transform(X_train)\n",
    "    X_val_transformed = cox_box_model.transform(X_val)\n",
    "\n",
    "    # X_train_transformed = scaler.fit_transform(X_train_transformed)\n",
    "    # X_val_transformed = scaler.transform(X_val_transformed)\n",
    "\n",
    "    return X_train_transformed, X_val_transformed\n",
    "\n",
    "\n",
    "def create_tally(X_train, X_val, y_train, y_val, models, names):\n",
    "    \"\"\"\n",
    "    This function performs cross-validation on multiple models and returns a dataframe with the mean and standard deviation of accuracy, precision, recall, and f1 score for each model.\n",
    "    \"\"\"\n",
    "    X = pd.concat([X_train, X_val])\n",
    "    y = pd.concat([y_train, y_val])\n",
    "    # if CAT_GAMBLING column has strings, map them to integers\n",
    "    if X['CAT_GAMBLING'].dtype == 'object':\n",
    "        X = map_gambling(X)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    stats = pd.DataFrame(\n",
    "        columns=['model', 'accuracy', 'accuracy_std', 'precision', 'precision_std', 'recall', 'recall_std', 'f1',\n",
    "                 'f1_std'])\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "        accuracy = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "        for train_index, val_index in skf.split(X, y):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "            X_train_transformed, X_val_transformed = cox_box_transform(X_train, X_val)\n",
    "            model.fit(X_train_transformed, y_train)\n",
    "            y_pred = model.predict(X_val_transformed)\n",
    "\n",
    "            accuracy.append(accuracy_score(y_val, y_pred))\n",
    "            precision.append(precision_score(y_val, y_pred))\n",
    "            recall.append(recall_score(y_val, y_pred))\n",
    "            f1.append(f1_score(y_val, y_pred))\n",
    "\n",
    "        new_row = {'model': name,\n",
    "                   'accuracy': np.mean(accuracy),\n",
    "                   'accuracy_std': np.std(accuracy),\n",
    "                   'precision': np.mean(precision),\n",
    "                   'precision_std': np.std(precision),\n",
    "                   'recall': np.mean(recall),\n",
    "                   'recall_std': np.std(recall),\n",
    "                   'f1': np.mean(f1),\n",
    "                   'f1_std': np.std(f1)}\n",
    "        stats = pd.concat([stats, pd.DataFrame([new_row])])\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def validate(X_train, X_test, y_train, y_test, models, names):\n",
    "    \"\"\"\n",
    "    This function fits each model with the training data, makes predictions on the test data, and calculates the accuracy, precision, recall, and f1 score.\n",
    "    It returns a dataframe with these metrics for each model.\n",
    "    \"\"\"\n",
    "    score = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "\n",
    "    X_train, X_test = cox_box_transform(X_train, X_test)\n",
    "    for m, n in zip(models, names):\n",
    "        ac, pr, re, f1 = get_my_metrics(m, X_train, X_test, y_train, y_test)\n",
    "        new_row = {'model': n, 'accuracy': ac, 'precision': pr, 'recall': re, 'f1': f1}\n",
    "        score = pd.concat([score, pd.DataFrame(new_row, index=[0])])\n",
    "    return score\n",
    "\n",
    "\n",
    "def prepare_score(score):\n",
    "    \"\"\"\n",
    "    This function reshapes the score dataframe from wide format to long format for visualization.\n",
    "    \"\"\"\n",
    "    score = pd.melt(score, id_vars=['model'], value_vars=['accuracy', 'precision', 'recall', 'f1'])\n",
    "    return score\n",
    "\n",
    "\n",
    "def create_visualization(score):\n",
    "    \"\"\"\n",
    "    This function creates a bar plot of the model performance metrics.\n",
    "    \"\"\"\n",
    "    s = prepare_score(score)\n",
    "    sns.set(rc={'figure.figsize': (10, 5)})\n",
    "    sns.barplot(x='model', y='value', hue='variable', data=s)\n",
    "    plt.title('Model Performance')\n",
    "    plt.ylabel('Score in each metric')\n",
    "    plt.xlabel('Model')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='Metrics')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:15:07.643476Z",
     "start_time": "2024-04-21T17:15:07.236627Z"
    }
   },
   "id": "6e2370d51a1a4897"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 13\u001B[0m\n\u001B[1;32m      6\u001B[0m models\u001B[38;5;241m=\u001B[39m[LogisticRegression(penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m, C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m),\n\u001B[1;32m      7\u001B[0m         SVC(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrbf\u001B[39m\u001B[38;5;124m'\u001B[39m, C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m),\n\u001B[1;32m      8\u001B[0m         RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m200\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m, min_samples_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, criterion\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgini\u001B[39m\u001B[38;5;124m'\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m),\n\u001B[1;32m      9\u001B[0m         DecisionTreeClassifier(min_samples_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, criterion\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)]\n\u001B[1;32m     11\u001B[0m names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLogistic Regression\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSVM\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRandom Forest\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDecision Tree\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 13\u001B[0m score\u001B[38;5;241m=\u001B[39m\u001B[43mvalidate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_for_validators\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_for_validators_encoded\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mClass_BARBUNYA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m score\n",
      "Cell \u001B[0;32mIn[8], line 135\u001B[0m, in \u001B[0;36mvalidate\u001B[0;34m(X_train, X_test, y_train, y_test, models, names)\u001B[0m\n\u001B[1;32m    133\u001B[0m X_train, X_test \u001B[38;5;241m=\u001B[39m cox_box_transform(X_train, X_test)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m, n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(models, names):\n\u001B[0;32m--> 135\u001B[0m     ac, pr, re, f1 \u001B[38;5;241m=\u001B[39m \u001B[43mget_my_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m     new_row \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m: n, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: ac, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m'\u001B[39m: pr, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m'\u001B[39m: re, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m: f1}\n\u001B[1;32m    137\u001B[0m     score \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([score, pd\u001B[38;5;241m.\u001B[39mDataFrame(new_row, index\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m])])\n",
      "Cell \u001B[0;32mIn[8], line 57\u001B[0m, in \u001B[0;36mget_my_metrics\u001B[0;34m(model, X_train, X_val, y_train, y_val)\u001B[0m\n\u001B[1;32m     54\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val)\n\u001B[1;32m     56\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_val, y_pred)\n\u001B[0;32m---> 57\u001B[0m precision \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m recall \u001B[38;5;241m=\u001B[39m recall_score(y_val, y_pred)\n\u001B[1;32m     59\u001B[0m f1 \u001B[38;5;241m=\u001B[39m f1_score(y_val, y_pred)\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    211\u001B[0m         )\n\u001B[1;32m    212\u001B[0m     ):\n\u001B[0;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    223\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2182\u001B[0m, in \u001B[0;36mprecision_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   2015\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   2016\u001B[0m     {\n\u001B[1;32m   2017\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2042\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2043\u001B[0m ):\n\u001B[1;32m   2044\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[1;32m   2045\u001B[0m \n\u001B[1;32m   2046\u001B[0m \u001B[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2180\u001B[0m \u001B[38;5;124;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[1;32m   2181\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2182\u001B[0m     p, _, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2183\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2184\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2187\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprecision\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2189\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2192\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1767\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1604\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[1;32m   1605\u001B[0m \n\u001B[1;32m   1606\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1764\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1766\u001B[0m _check_zero_division(zero_division)\n\u001B[0;32m-> 1767\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1769\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1770\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1542\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1539\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[1;32m   1540\u001B[0m \u001B[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001B[39;00m\n\u001B[1;32m   1541\u001B[0m \u001B[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001B[39;00m\n\u001B[0;32m-> 1542\u001B[0m present_labels \u001B[38;5;241m=\u001B[39m \u001B[43munique_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1544\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/multiclass.py:116\u001B[0m, in \u001B[0;36munique_labels\u001B[0;34m(*ys)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# Check that we don't mix string type with number type\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(label, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m ys_labels)) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMix of label input types (string and number)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(\u001B[38;5;28msorted\u001B[39m(ys_labels))\n",
      "\u001B[0;31mValueError\u001B[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "# create list of model with random state 42\n",
    "# create logistic regression with l1 penalty and c=100\n",
    "# create svm with rbf kernel and c=1000 and gamma=0.1\n",
    "#create random forest with n_estimators=200 and max_depth=25, min_samples_split=5, criterion='log_loss'\n",
    "# create decision tree with min_samples_split=10, criterion='entropy', max_depth=20\n",
    "models=[LogisticRegression(penalty='l2', C=100, random_state=42),\n",
    "        SVC(kernel='rbf', C=1000, gamma=0.1, random_state=42),\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_split=5, criterion='gini', random_state=42),\n",
    "        DecisionTreeClassifier(min_samples_split=10, criterion='entropy', max_depth=20, random_state=42)]\n",
    "\n",
    "names=['Logistic Regression', 'SVM', 'Random Forest', 'Decision Tree']\n",
    "\n",
    "score=validate(X_train, X_for_validators, y_train, y_for_validators_encoded['Class_BARBUNYA'], models, names)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T17:40:58.014181Z",
     "start_time": "2024-04-21T17:40:57.710393Z"
    }
   },
   "id": "66f9b75bb361658b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
